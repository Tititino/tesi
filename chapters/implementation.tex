\chapter{Implementation}\label{chapter:implementation}
We now describe the main implementation details of our prover.
During this section, to distinguish the variables from \ref{def:bool expr} from Prolog's ones, we will always refer to the latter as Prolog variables.
When explaining the code we will use some common names for Prolog variables:
\begin{itemize}
	\item \texttt{A} is a set of unrestricted atoms, which purpose will be explained in Section \ref{sec:identity};
	\item \texttt{U} is a set of unrestricted formulae; this more or less corresponds to $\Psi$ from \S\ref{chapter:calculus};
	\item \texttt{F}, \texttt{F1}, ..., are formulae, and \texttt{Fs} and \texttt{D} are a lists of them; these more or less correspond to $\Delta$ and $\Gamma$ from \S\ref{chapter:calculus};
	\item \texttt{S} is the queue of currently usable unrestricted formulae, which purpose will be explained in Section \ref{sec:decide};
	\item \texttt{L} is a list of constraints.
\end{itemize}

\section{Why Prolog}
Prolog as a language and as an environment has been historically tied to automated theorem proving for its ability to express backtracking algorithms naturally.
% In particular we chose SWI-Prolog because it offers a comprehensive and mature free Prolog environment.
Most Prolog implementations also support CLP (constraint logic programming) through dedicated libraries.
These allow to express constraints referring some attributes of Prolog variables in the body of the clauses; in our case we will use \CLPB{} \cite{clpb}, which provides tools to deal with boolean constraints.
Which, in this context, are expressions made of Prolog variables and the constants 1 and 0, respectively true and false.
The allowed operators are the usual ones one would expect; in our case we will use exclusively conjunction, negation and equality, respectively:
\begin{minted}{prolog}
X * Y.
~ X.
X =:= Y.
\end{minted}
Usually constraints will be accumulated in a list, for this reason \CLPB{} provides the functor \texttt{*(L)} to express the conjunction of its members.
The main predicate of the library is \texttt{sat/1}, which checks for the satisfiability of a constraint.
Since we only deal with conjunctions we define the helper predicate \texttt{check/1}
\begin{minted}{prolog}
check(L) :-
  sat(*(L)).
\end{minted}
The better understand how the predicate works, we give some examples:
\begin{minted}{prolog}
?- check([X * Y =:= 1, X =:= 0]).
false.
?- check([X * Y =:= 0]).
sat(1#X*Y).
?- check([X * Y =:= 0, X =:= 1]).
X = 1,
Y = 0.
\end{minted}
Here three different outcomes can be seen:
\begin{itemize}
	\item the first case is unsatisfiable, so the predicate fails;
	\item the second case is not instantiated enough and so the constraints just get reduced;
	\item the third case shows how one constraint (\texttt{X =:= 1}) can force a Prolog variable to be unified to a value.
\end{itemize}
It is important to point out, altought abvious, that constraint satisfaction also unifies the Prolog variables to their assigned value.
This mechanism is used to implcitly deal with the propagation of solutions.

We use the library with the flag \texttt{clpb\_monotonic} set to \texttt{true}.
This makes the algorithm many orders of magnitude faster but mandates that all Prolog variables be wrapped by the functor \texttt{v/1}.
This small explanation sums up the extent of the library we use in our prover.

\section{Formula transformations}
Before beginning the proof a sequent passes through a number of transformations.
These transformations both preprocess the sequent to a more convenient form, and also add information about the sub-formulae.

As a first transformation the sequent gets normalized into a sequent in negated normal form (NNF) as defined in Definition \ref{def:nnf}.
Normalization is a common technique -- used in all the provers we compare with.
The implementation mirrors exactly the transformation from two-sided judgment to one-sided judgment of Section \ref{sec:normalization}:
\begin{enumerate}
	\item the left sequent is negated and appended to the right sequent, implemented by the predicate \texttt{negate\_premises/3};
	\item the predicate \texttt{nnf/2}, which encodes the DeMorgan rules, is mapped recursively over the new sequent.
\end{enumerate}
From an implementation point of view the purpose of normalization is to reduce the number of available choices the prover has at a certain moment, although by doing so we sacrifice some of the structure of the formula.

Next, to each formula we assign its why-not height, a measure borrowed from APLL's implementation.
\begin{define}[Why-not height]
	\label{def:why-not height}
	Why-not height is the maximum number of nested ``why-not''s in a formula, or
	$$ \mathrm{wnh}(\phi) = 
	\begin{cases}	
		0 & \text{if }\phi \in \{\llbot, \lltop, \llone, \llzero\} \\
		\max(\mathrm{wnh}(\phi_1), \mathrm{wnh}(\phi_2)) & \text{if } \phi \in \{ \phi_1 \llten \phi_2, \phi_1 \llpar \phi_2, \phi_1 \llplus \phi_2, \phi_1 \llwith \phi_2 \} \\
		\mathrm{wnh}(\phi_1) & \text{if }\phi \in \{ \llnot{\phi_1}, \llbang{\phi_1}\} \\
		1 + \mathrm{wnh}(\phi_1) & \text{if }\phi \in \{ \llwn{\phi_1} \} 
	\end{cases}
	$$
\end{define}
The purpose of this attribute is to guide the prover to the reasonably simpler choice -- the one with the least nested exponentials -- at different times during proof search.
This happens in three ways: 
\begin{itemize}
	\item When a rule generates two branches ($\displayten$, $\displaywith$), the branch associated to the formula with the least why-not height is tried first.
		This will presumably make the prover choose the simpler branch of the two, making it so we can fail early if the branch turns out to be false.
		An example of this is Section \ref{sec:asy phase}.
	\item In the case of plus ($\llplus$), the branch associated to the least why-not height is tried first; this makes it so we can continue if the branch turns out to be true, ignoring the other harder branch.
	\item During the $D_2$ rule, the exponentials are tried in order of ascending why-not height.
		This process is further explained in Section \ref{sec:decide}.
\end{itemize}
After this transformation formulae are attribute trees with at each node the why-not height.
For example the formula \texttt{*(a, ?(b))} becomes \texttt{*(a-0, ?(b-0)-1)-1}, or
\begin{figure}[H]
	\centering
	\begin{tikzpicture}
		\node (root1) {\texttt{*}}
			child { node {\texttt{a}} }
			child { 
				node {\texttt{?}}
				child { node {\texttt{b}} }
			};

		\node (arrow) at ([xshift=1.25cm] root1-2.west) {$\overset{\mathrm{wnh}}{\Rightarrow}$};
		\node (root2) at ([xshift=4cm] root1.west) {\texttt{*-1}}
			child { node {\texttt{a-0}} }
			child { 
				node {\texttt{?-1}}
				child { node {\texttt{b-0}} }
			};

	\end{tikzpicture}
\end{figure}

As a third and final transformation, each formula gets annotated as in Definition \ref{def:annotated}.
The process of annotation is implemented by the predicate \texttt{annotate/3}.
This also returns the initial constraints, which set each formula in the sequent to ``used''; thus stating that in the proof each and every formula must be used.
% continuo?

\section{Helper predicates}\label{sec:helper}
The prover needs a series of helper predicates ranging from predicates that just implement $\phi\;\mathrm{asy}$ from Definition \ref{def:focusing predicates}, to ones which aid the generation of constraints.
In particular we now cover the implementation of the splitting function from Definition \ref{def:split}
\begin{minted}[linenos]{prolog}
%! split_ctx(+[AFs], -[AFs], -[AFs], -[Cns], -[Cns]) is det.
split_ctx(Afs, Pos, Neg, PCns, NCns) :-
  maplist([ af(F, N, E)
          , af(F, VarPos, Y)
          , af(F, VarNeg, Z)
          , v(Y) =:= v(X) * v(E)
          , v(Z) =:= (~ v(X)) * v(E)
          ]>>(
  	     gensym(x, V),
  	     atomic_list_concat([N, V], '.', VarPos),
  	     atomic_list_concat([N, V], '.~', VarNeg)
  ), Afs, Pos, Neg, PCns, NCns).
\end{minted}
The code itself is nothing special, consisting of a simple map over the list of formulae generating the constraints.
What is important is that the snippet above shows the clear distinction between variable names -- represented by atoms (lines 10-11), and the value of a variable -- represented by Prolog variables (lines 4-5).
This separation of name and value is needed because -- after checking the constraints -- the solver unifies the Prolog variables to their values if it finds a valid assignment; the purpose of the atom is then to associate the variable value to its name if the final proof tree.

Finally, it must be noted that there is no predicate implementing the concept of two coinciding assignments (Definition \ref{def:coincidence}): this -- as mentioned before -- is implicitly handled by Prolog's unification mechanism.

\section{Focusing}\label{sec:focusing impl}
Focusing is implemented by two mutually defined predicates: \texttt{async/8} and \texttt{focus/8}, implementing respectively the asynchronous and the synchronous rules of Figure \ref{fig:calculus}.
The structure of these two predicates reflects almost exactly that of the sequents.

During the asynchronous phase we have two lists: \texttt{Fs} and \texttt{D}, representing $\Gamma$ and $\Delta$.
The asynchrnous rules always work on the head of \texttt{Fs}, breaking it down into its sub-formulae.
This process can be seen for example in the predicate for with ($\displaywith$):
\begin{minted}[linenos]{prolog}
async(A, U, D, [F|Fs], S, M, L) :-
  F = af(((F1-H1) & (F2-H2))-_), N, E), !,
  ( H2 > H1	
  -> async(A, U, D, [af((F1-H1), N, E)|Fs], S, M, [v(E) =:= 1|L]), 
     async(A, U, D, [af((F2-H2), N, E)|Fs], S, M, [v(E) =:= 1|L]) 
  ;  async(A, U, D, [af((F2-H2), N, E)|Fs], S, M, [v(E) =:= 1|L]),
     async(A, U, D, [af((F1-H1), N, E)|Fs], S, M, [v(E) =:= 1|L])
  ).
\end{minted}
Here, we chose this particular rule to also show how the prover is guided using why-not height (line 3) as mentioned in Definition \ref{def:why-not height}.
Compare this with the $\llwith$ rule in Figure \ref{fig:calculus}.
The cut at line 2 is important to guarantee the determinism of the asynchronous phase and is present in all the rules for the negative connectives.

If a formula cannot be further be broken apart -- i.e. it is either an atom, a negated atom, or it has a top-level synchronous connective -- then it is put to the side in \texttt{D}.
This process goes as long as \texttt{Fs} is not empty.

When each formula is moved from \texttt{Fs} to \texttt{D}, the phase switches and the focusing process begins: a formula is chosen from either \texttt{D} or \texttt{U} by applying one of the decide rules.
This formula gets broken down until either an asynchronous connective or a negated atom is left. 
Unlike the asynchronous phase, the rules applied in this phase are non-deterministic and may be backtracked.
Other than this the implementation of the predicate \texttt{focus/8} is almost the same as \texttt{async/8}: the formula is broken down into its sub-formulae, and -- if necessary -- the why not heights are used to guide the proof searc.
The decide rules will be discussed further ahead in Section \ref{sec:decide}.

\subsection{Identity rules}\label{sec:identity}
This process of alternating asynchronous and synchronous phases in classic focusing goes on until only a positive literal (in our case a negated atom) in \texttt{Fs} is left; and the corresponding negative literal (in our case just an atom) in either \texttt{U} or \texttt{D}.
When this happens the axioms -- rules $I_1$ or $I_2$ -- are applied to close the branch of the proofs.
In our case when we are focusing and we have a positive literal in \texttt{Fs}, we check if the corresponding negative literal exists in \texttt{D}.
If this is true, then the variables of all the other formulae in \texttt{D} are set to zero using the predicate \texttt{set\_to\_zero/2} defined in Section \ref{sec:helper}, and the constraints are checked.
This is encoded by the clause 
\begin{minted}[linenos]{prolog}
focus(A, U, D, F, _, _, L) :-
  F = af(((~ T)-_), _, E1),
  is_term(T),
  select(af((T-_), _, E2), D, D1),
  set_to_zero(D1, Dz),
  append([v(E1) =:= 1, v(E2) =:= 1|Dz], L, Cns),
  check(Cns).
\end{minted}
where \texttt{set\_to\_zero/2} (line 4) is to be interpreted as $\avail{-}$.
A slightly different approach is taken if instead a correspondence is found in \texttt{A} instead of \texttt{D}.
Here \texttt{A} is a special set containing just unrestricted atoms.
This is a small modification to APLL's algorithm based on the fact that once negative literals are put in a sequent they can never leave it.

\subsection{Decide rules}\label{sec:decide}
For the decide rules, particularly for $D_2$, we use a modified version of APLL's algorithm defined in Section \ref{sec:apll}.
The method consists of not using directly the set $\Psi$ in the $D_2$ rule, but instead a queue of ordered unrestricted formulae which can be refilled only a certain number of times per-branch.
This can be seen in the definition of the rule \texttt{decide\_2} for the \texttt{async/8} predicate
\begin{minted}{prolog}
async(A, U, D, [], [H|T], M, L) :-
  \+ U = [],
  gensym(x, X),
  focus(A, U, D, af(H, X, E), T, M, [v(E) =:= 1|L]).
async(A, U, D, [], [_|T], M, L) :-
  \+ U = [],
  async(A, U, D, [], T, M, L).
async(A, U, D, [], [], M, L) :-
  \+ U = [],
  refill(U, M, S, M1),
  early_stop(A, U, D, S, M1, L).
\end{minted}
Here the fifth argument is the queue and the sixth is the bound.
Two cases arise:
\begin{itemize}
	\item if \texttt{S = []} and \texttt{M > 0} then the sequent of unrestricted formulae \texttt{U} is taken and it is sorted based on why-not height.	% cambio persona
		This can be seen in the predicate \texttt{refill/4}
		\begin{minted}{prolog}
refill(U, M, S, M1) :-
  \+ M = 0,
  \+ U = [], 
  sort(2, @=<, U, S), 
  M1 is M - 1.
		\end{minted}
		This new list of unrestricted formulae becomes the new \texttt{S} and \texttt{M} is decreased.
		Otherwise if if \texttt{M} is 0 (line 2) the branch fails.
	\item if \texttt{S} is not empty, then the first formula in the queue is extracted and added to the working set.	% sistemo
		If the branch fails the formula gets discarded and the next one in the queue is tried.	% sistemo
\end{itemize}
In particular, if the queue \texttt{S} is refilled, we do not directly call \texttt{async/8}, but instead call the predicate \texttt{early\_stop/7} (line 11), defined as:
\begin{minted}{prolog}
early_stop(_, _, _, [], _, _) :-
  false.
early_stop(A, U, D, [H|T], M, L) :-
  gensym(x, X),
  focus(A, U, D, af(H, X, E), T, M, [v(E) =:= 1|L]).
early_stop(A, U, D, [_|T], M, L) :-
  early_stop(A, U, D, T, M, L).
\end{minted}
This is due the simple fact that if the branch was not provable and we instead called directly \texttt{async/8} at line 11, we would try to refill the branch \texttt{M} times.
What \texttt{early\_stop/7} does is fail if the queue has just been refilled and it turns out the branch was not provable.

All the rules $D_1$, $I_1$ are defined before the unrestricted counterparts, so that they are tried first.

\section{Building the tree}
In the listings above we omitted one parameter from the calls to \texttt{focus/8} and \texttt{async/8}, which purpose is to build the proof tree.
For example in the clause for par ($\displaypar$)
\begin{minted}{prolog}
async(A, U, D, [F|Fs], S, M, L, node(par, A, U, D, [F|Fs], [T])) :- 
  F = af(((F1 / F2)-_), N, E), !,
  Fs1 = [af(F1, N, E), af(F2, N, E)|Fs],
  async(A, U, D, Fs1, S, M, [v(E) =:= 1|L], T).
\end{minted}
we can see clearly the structure of one node of the tree: a label, the context and an -- optionally empty -- list of sub-trees.
A leaf is just a node with an empty list of sub-trees.

This term can be used in the end to reconstruct the actual proof tree by visiting it and -- for each formula of each node -- querying whether its variable is set to one, deleting it otherwise (this process is the same used in the proof for Theorem \ref{thm:soundness}).
A classic proof tree without the focusing infrastructure may be built by removing all the nodes regarding the phases (i.e. $\displaytoasy$ $\displaytodelta$ and decide rules) and by rebuilding the original sequent by appending \texttt{A}, \texttt{U}, \texttt{D} and \texttt{Fs} together as explained in \cite{Focusing}. 
A more sophisticated algorithm may even cancel out unwanted unrestricted formulae, that otherwise remain lingering in the sequent.

